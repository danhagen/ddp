[Created 2019/05/29 at 17:34.12]

##############################
########### Notes ############
##############################

		Upon reading the DDP description from Tassa et al (2014), I changed the self.LearningRate parameter to 1 and only applied it to the feedforward modification -Quu_inv*Qu. The paper notes that this should be set at one and then iteratively decreased. It appears from the plot of the cost that this almost instantly drops it to the region of the minimal cost. We will now try this with the MPC and see what happens. 

##############################
######### Parameters #########
##############################

		Horizon: 300
		SimulationDuration: 10
		dt: 0.01
		U_o: None
		p_target: [[0.78539816]
 [0.        ]]
		LearningRate: 1
		Q_f: [[500   0]
 [  0  50]]
		R: [[ 0.002 -0.001]
 [-0.001  0.002]]
		InputBounds: [[0, 1059.9], [0, 2047.1]]
		ConstraintCoefficient: 5
		PlotResults: True
		AnimateResults: True
		ReturnAllResults: True
		NumberOfIterations: 100

##############################
